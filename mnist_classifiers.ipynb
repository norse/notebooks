{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7IYU0Bqomb2"
   },
   "source": [
    "# Training an MNIST classifier\n",
    "\n",
    "This tutorial introduces the [norse](norse.ai) library by going through the \"Hello World\" of deep-learning: How to classify hand-written digits. Norse is based on the popular pytorch deep-learning library and this is in fact the only requirement you need to build your own models with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wu93JGgT2CJ2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rmUJSdzqypr"
   },
   "source": [
    "We can simply install Norse through pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPb7tCeX2Jkb",
    "outputId": "27c75437-737b-43f3-eb76-10ec7e7983ad"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet norse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrZ71gW94b1O"
   },
   "source": [
    "## Integrating point neuron model equations\n",
    "\n",
    "Spiking neuron models are given as (typically very simple) systems of ordinary differential\n",
    "equations. A common example used is the so called current based leaky integrate and fire neuron model (LIF). Its differential equation is given by\n",
    "\\begin{align*}\n",
    "\\dot{v} &= -(v - v_\\text{reset}) + I \\\\\n",
    "\\dot{I} &= -I + I_\\text{in}\n",
    "\\end{align*}\n",
    "together with jump and transition equations, that specify when a jump occurs and\n",
    "how the state variables change. A prototypical equation is a leaky integrator\n",
    "with constant current input $I_\\text{in}$, with jump condition $v - 1 = 0$ and transition equation $v^+ - v^- = -1$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ZzPRyc8E2M8a",
    "outputId": "7623e613-923f-451a-f8bf-f1c05ad72912"
   },
   "outputs": [],
   "source": [
    "from norse.torch.functional import lif_step, lift, lif_feed_forward_step, lif_current_encoder, LIFParameters\n",
    "\n",
    "N = 1 # number of neurons to consider\n",
    "T = 100 # number of timesteps to integrate\n",
    "\n",
    "p = LIFParameters()\n",
    "v = torch.zeros(N) # initial membrane voltage\n",
    "input_current = 1.1 * torch.ones(N)\n",
    "\n",
    "voltages = []\n",
    "\n",
    "for ts in range(T):\n",
    "  z, v = lif_current_encoder(input_current, v, p)\n",
    "  voltages.append(v)\n",
    "\n",
    "voltages = torch.stack(voltages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the voltages over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"v\")\n",
    "plt.xlabel(\"time [ms]\")\n",
    "plt.plot(voltages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOYVGOvhrDty"
   },
   "source": [
    "## MNIST dataset\n",
    "\n",
    "A common toy dataset to test machine learning approaches on is the MNIST handwritten digit recognition dataset. The goal is to distinguish handwritten digits 0..9 based on a 28x28 grayscale picture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420,
     "referenced_widgets": [
      "a39cccabae994485b9b3f0866d6f1891",
      "48509a5c085441f29d908f03e17104f1",
      "49e4961d66cf49d096fe542250bd7ea4",
      "699927de0a9a44438c7f77f53c80ca41",
      "be29cb04ef804c31acbe5b57a4254f8e",
      "18f3adf705754ed486b4860c38a443a9",
      "3313b75ccbea4d1f89409d4abb47b8f6",
      "d1268b0592cd4f9a9a4c04c939dc0402",
      "999ca0343fbd4693bfeb6e75df29aaa4",
      "2537d663e9a941cdb3239daa8f463145",
      "06c79d8b76d646f597091e64b3ac8a7c",
      "adf7256611d04523a8d77a6c0079db52",
      "34055b8bbea048378f7e71a498cba0f8",
      "eb3b3c6cf9024c7899fbc7f588dec2e0",
      "d3b69d17635c4be09e1e66d8bf3c190f",
      "700180bf289944e4898a6ea9bb7e6815",
      "b38e0b3b846d44f08a68884a6ec894eb",
      "83d347927a6147f8ae69818bfa66fd88",
      "58a275f42e63442fa5306f85ee09e094",
      "77fd86441e54485dad7dfee7b3b26d2b",
      "89a9086e97834567b65d188efdd0fe66",
      "dae7cfd7c37f4278b661c9fd14de3aed",
      "bbd4e89f0ed0472f83ebe824f6177020",
      "256419cbcfde4ee8bfe6fc35beb236ee",
      "d4a6f8b8cfc34899a809581d3f10b414",
      "40735b0849ad472b893f465085013963",
      "0f11348c44cc48a98135e4e5d2d5de73",
      "d1aa16b66d21488d93b9b54141190798",
      "23235a7e41c547f49395137b57387d69",
      "a4c87414f66747bb9532195c6569364b",
      "b33e85cc5a304bd798bbd294bae3e236",
      "50891ba2e81542eeba75ed311f1398ca"
     ]
    },
    "id": "RPs81D-QrFWV",
    "outputId": "0eb067e3-fc00-486d-d618-7ca41bd70535",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\".\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        root=\".\",\n",
    "        train=False,\n",
    "        transform=transform,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_STHa4ethi4"
   },
   "source": [
    "## Encoding Input Data\n",
    "\n",
    "One of the distinguishing features of spiking neural networks is that they\n",
    "operate on temporal data encoded as spikes. Common datasets in machine learning\n",
    "of course don't use such an encoding and therefore make a encoding step necessary. Here we choose to treat the grayscale value of an MNIST image\n",
    "as a constant current to produce input spikes to the rest of the network.\n",
    "Another option would be to interpret the grayscale value as a spike probabilty\n",
    "at each timestep.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVYrXB00-fqO"
   },
   "source": [
    "### Constant Current Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHwqgEFvZaoQ"
   },
   "outputs": [],
   "source": [
    "from norse.torch import ConstantCurrentLIFEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHH7pA86l_nL"
   },
   "source": [
    "We can easily visualise the effect of this choice of encoding on a sample image in the training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "cbYBEbBsTNam",
    "outputId": "628bf729-fe32-4d33-de82-a6fcc1257eab"
   },
   "outputs": [],
   "source": [
    "img, label = train_data[1]\n",
    "\n",
    "plt.matshow(img[0])\n",
    "plt.colorbar()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "FWAPfbM7T6lM",
    "outputId": "b7b067ea-b534-4017-bcfc-62c33691941b"
   },
   "outputs": [],
   "source": [
    "T = 32\n",
    "example_encoder = ConstantCurrentLIFEncoder(T)\n",
    "\n",
    "\n",
    "example_input = example_encoder(img)\n",
    "example_spikes = example_input.reshape(T,28*28).to_sparse().coalesce()\n",
    "t = example_spikes.indices()[0]\n",
    "n = example_spikes.indices()[1]\n",
    "\n",
    "plt.scatter(t, n, marker='|', color='black')\n",
    "plt.ylabel('Input Unit')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouwn94PQipIw"
   },
   "source": [
    "### Poisson Encoding\n",
    "\n",
    "As can be seen from the spike raster plot, this kind of encoding does not produce spike patterns which are necessarily biologically realistic. We could rectify this situation by employing cells with varying threshholds and a finer integration time step. Alternatively we can encode the grayscale input images into poisson spike trains\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hqWN47egmir"
   },
   "outputs": [],
   "source": [
    "from norse.torch import PoissonEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOlfpqnBjIrE"
   },
   "source": [
    "This produces a more biological plausible input pattern, as can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "u74m9sishnkF",
    "outputId": "341d9438-236f-46a2-b234-e8edddae8c15"
   },
   "outputs": [],
   "source": [
    "T = 32\n",
    "example_encoder = PoissonEncoder(T, f_max=20)\n",
    "\n",
    "example_input = example_encoder(img)\n",
    "example_spikes = example_input.reshape(T,28*28).to_sparse().coalesce()\n",
    "t = example_spikes.indices()[0]\n",
    "n = example_spikes.indices()[1]\n",
    "\n",
    "plt.scatter(t, n, marker='|', color='black')\n",
    "plt.ylabel('Input Unit')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9QNqiwIx3HH"
   },
   "source": [
    "### Spike Latency Encoding\n",
    "\n",
    "Yet another example is a spike latency encoder. In this case each input neuron spikes only once, the first time the input crosses the threshhold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trq4AeDTyKNu"
   },
   "outputs": [],
   "source": [
    "from norse.torch import SpikeLatencyLIFEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "JvqFTcvZzfpS",
    "outputId": "b1f9eeb0-0b77-4e34-a18e-8f6292dc1dd4"
   },
   "outputs": [],
   "source": [
    "T = 32\n",
    "example_encoder = SpikeLatencyLIFEncoder(T)\n",
    "\n",
    "\n",
    "example_input = example_encoder(img)\n",
    "example_spikes = example_input.reshape(T,28*28).to_sparse().coalesce()\n",
    "t = example_spikes.indices()[0]\n",
    "n = example_spikes.indices()[1]\n",
    "\n",
    "plt.scatter(t, n, marker='|', color='black')\n",
    "plt.ylabel('Input Unit')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNEqcSNH2WfP"
   },
   "source": [
    "## Defining a Network\n",
    "\n",
    "Once the data is encoded into spikes, a spiking neural network can be constructed in the same way as a one would construct a recurrent neural network.\n",
    "Here we define a spiking neural network with one recurrently connected layer\n",
    "with `hidden_features` LIF neurons and a readout layer with `output_features` and leaky-integrators. As you can see, we can freely combine spiking neural network primitives with ordinary `torch.nn.Module` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN9Sm4rJtgc7"
   },
   "outputs": [],
   "source": [
    "from norse.torch import LIFParameters, LIFState\n",
    "from norse.torch.module.lif import LIFCell, LIFRecurrentCell\n",
    "# Notice the difference between \"LIF\" (leaky integrate-and-fire) and \"LI\" (leaky integrator)\n",
    "from norse.torch import LICell, LIState\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "class SNNState(NamedTuple):\n",
    "    lif0 : LIFState\n",
    "    readout : LIState\n",
    "\n",
    "\n",
    "class SNN(torch.nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features, record=False, dt=0.001):\n",
    "        super(SNN, self).__init__()\n",
    "        self.l1 = LIFRecurrentCell(\n",
    "            input_features,\n",
    "            hidden_features,\n",
    "            p=LIFParameters(alpha=100, v_th=torch.tensor(0.5)),\n",
    "            dt=dt                     \n",
    "        )\n",
    "        self.input_features = input_features\n",
    "        self.fc_out = torch.nn.Linear(hidden_features, output_features, bias=False)\n",
    "        self.out = LICell(dt=dt)\n",
    "\n",
    "        self.hidden_features = hidden_features\n",
    "        self.output_features = output_features\n",
    "        self.record = record\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        seq_length, batch_size, _, _, _ = x.shape\n",
    "        s1 = so = None\n",
    "        voltages = []\n",
    "\n",
    "        if self.record:\n",
    "          self.recording = SNNState(\n",
    "              LIFState(\n",
    "                z = torch.zeros(seq_length, batch_size, self.hidden_features),\n",
    "                v = torch.zeros(seq_length, batch_size, self.hidden_features),\n",
    "                i = torch.zeros(seq_length, batch_size, self.hidden_features)\n",
    "              ),\n",
    "              LIState(\n",
    "                v = torch.zeros(seq_length, batch_size, self.output_features),\n",
    "                i = torch.zeros(seq_length, batch_size, self.output_features)\n",
    "              )\n",
    "          )\n",
    "\n",
    "        for ts in range(seq_length):\n",
    "            z = x[ts, :, :, :].view(-1, self.input_features)\n",
    "            z, s1 = self.l1(z, s1)\n",
    "            z = self.fc_out(z)\n",
    "            vo, so = self.out(z, so)\n",
    "            if self.record:\n",
    "              self.recording.lif0.z[ts,:] = s1.z\n",
    "              self.recording.lif0.v[ts,:] = s1.v\n",
    "              self.recording.lif0.i[ts,:] = s1.i\n",
    "              self.recording.readout.v[ts,:] = so.v\n",
    "              self.recording.readout.i[ts,:] = so.i\n",
    "            voltages += [vo]\n",
    "\n",
    "        return torch.stack(voltages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXzSK17BrmjT"
   },
   "source": [
    "We can visualize the output produced by the recurrent spiking neural network on the example input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "nVq-2OD0pSnL",
    "outputId": "2d88ed7e-06ec-4424-ea23-8991e2da0d36"
   },
   "outputs": [],
   "source": [
    "example_snn = SNN(28*28, 100, 10, record=True, dt=0.001)\n",
    "\n",
    "example_readout_voltages = example_snn(example_input.unsqueeze(1))\n",
    "voltages = example_readout_voltages.squeeze(1).detach().numpy()\n",
    "\n",
    "plt.plot(voltages)\n",
    "plt.ylabel('Voltage [a.u.]')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "dbLpIlYqtYJv",
    "outputId": "c1b97d2b-b2a6-41eb-f034-ee17f91d1c3c"
   },
   "outputs": [],
   "source": [
    "plt.plot(example_snn.recording.lif0.v.squeeze(1).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "pxK6Ds2Mt94j",
    "outputId": "fca1b29f-0e80-4ade-c709-2d8065e4508b"
   },
   "outputs": [],
   "source": [
    "plt.plot(example_snn.recording.lif0.i.squeeze(1).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq1mvp0ffIsI"
   },
   "source": [
    "## Decoding the Output\n",
    "\n",
    "The output of the network we have defined are $10$ membrane voltage traces. What remains to do is to interpret those as a probabilty distribution. One way of doing so is to determine the maximum along the time dimension and to then compute the softmax of these values. There are other options of course, for example to consider\n",
    "the average membrane voltage in a given time window or use a LIF neuron output layer and consider the time to first spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6j0wbwEmfbIw"
   },
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "    x, _ = torch.max(x, 0)\n",
    "    log_p_y = torch.nn.functional.log_softmax(x, dim=1)\n",
    "    return log_p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngp3zr5AstiH"
   },
   "source": [
    "An alternative way of decoding would be to consider only the membrane trace at the last measured time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Idsu-fAjYdn"
   },
   "outputs": [],
   "source": [
    "def decode_last(x):\n",
    "    x = x[-1]\n",
    "    log_p_y = torch.nn.functional.log_softmax(x, dim=1)\n",
    "    return log_p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1jcJ7LnrlUi"
   },
   "source": [
    "## Training the Network\n",
    "\n",
    "The final model is then simply the sequential composition of these three steps: Encoding, a spiking neural network and decoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRdRp3ZfAYIw"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, encoder, snn, decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.snn = snn\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.snn(x)\n",
    "        log_p_y = self.decoder(x)\n",
    "        return log_p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqxyhc_5Xpfg"
   },
   "source": [
    "We can then instantiate the model with the recurrent ```SNN``` network defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C4QeDXL9_qaB",
    "outputId": "533ce0f5-33fe-4cde-897b-218be6d43b9f"
   },
   "outputs": [],
   "source": [
    "T = 32\n",
    "LR = 0.002\n",
    "INPUT_FEATURES = 28*28\n",
    "HIDDEN_FEATURES = 100\n",
    "OUTPUT_FEATURES = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "model = Model(\n",
    "    encoder=ConstantCurrentLIFEncoder(\n",
    "      seq_length=T,\n",
    "    ),\n",
    "    snn=SNN(\n",
    "      input_features=INPUT_FEATURES,\n",
    "      hidden_features=HIDDEN_FEATURES,\n",
    "      output_features=OUTPUT_FEATURES\n",
    "    ),\n",
    "    decoder=decode\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM5btRjKdEEv"
   },
   "source": [
    "What remains to do is to setup training and test code. This code is completely independent of the fact that we are training a spiking neural network and in fact has been largely copied from the pytorch tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SXgntmL_rvHO"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "EPOCHS  = 5  # Increase this number for better performance \n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, max_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for (data, target) in tqdm(train_loader, leave=False):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.functional.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(losses)\n",
    "    return losses, mean_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtdcQi_18Xip"
   },
   "source": [
    "Just like the training function, the test function is standard boilerplate, common with any other supervised learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gca4ZzatApWD"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += torch.nn.functional.nll_loss(\n",
    "                output, target, reduction=\"sum\"\n",
    "            ).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "83471770562e4dc6a9c0203567a11738",
      "79a47e5c73884eaa95aa3cf1798bd34e",
      "e8815d2923f64385993f68ba2a0ff83a",
      "c9dddaf73fac46d78a2616763c3498ff",
      "a51b7d3fd61d450c89bc5525ce31c495",
      "9904c1cbdddf479a8491807d3810b4a0",
      "c65e235f0f21418b80d8df61fcea0229",
      "1cec1ba4c03342f29d6fa3bac1fdef79",
      "0db2860f929b4728a58a5a60a76d0661",
      "afe0f290c061434a9868f4f7884ecae4",
      "5a4f2f4068e3463fbcec7a8cfcc6d99c",
      "a4cbd02d8b47464a8fefab8bd4be1a4f",
      "1c76c1d0a7a443b89e34a6606b5db3e2",
      "6ffc4204c106450c82577624db006d7d",
      "ecce7c70c4bb41cb9984529e1ea836d9",
      "6a0653febe6443768d9f04693a6815dc",
      "ba0526a00832430696c50c3c3990ea52",
      "37ff024648ef4a328ab218827d1e5e8a",
      "f2581d6f8e014b7f8c47c9748966ddc5",
      "5f5c829842734e109a062d7822308738",
      "d307e64e0add463e8ec0fb8556c02532",
      "63d12d053b194af5a064c23916544fe6",
      "fdcd12c58ce34ac9a1d64132e9dfaade",
      "528b36c345eb4c16a043b3fcb0d26a02",
      "f82b17289112486fa1340b5d7dd14c0e",
      "dc0e7177ec804b0fb99b85d56eaf3ad5",
      "4f77245233e54f01a23d2070d049f63d",
      "ec712d288cee4f1eb2bcf6af2a2e3673",
      "ae87af3bb7014b19b0dd0c515a115724",
      "ee324024183546d5b5e563ceb5bcbd6e",
      "71f7be117e3840ed8ecd71c30b92ccd1",
      "0d985ad92a734753923318035caee6d8",
      "4e9e3649f45a4fd78cff0efb1a776c8d",
      "08d8223656ea4402851911a5b8b320b6",
      "120e2e6d1209454bac8a77dba77a3181",
      "983c4760eb4247f2b053b70fa8c470f8",
      "235c4ed216ef4bebbe5cbb45e5e8a432",
      "4e81dcf2a69e4255b68f96594a5d8f46",
      "e3233a8ac4b548b78d62f5312a624b39",
      "4690821d1e4744ce8a1e00bd92f612dd",
      "a01d369fee314a3390ee34d4c7c27c63",
      "21d8540ae0a5444f8cdca7d00d3b3034",
      "7bab9f7eead449d6b2f043fddeaeaa5f",
      "ef6ff21e1b8843939c97d844d8245330",
      "f239ddb5cf8a491d857d4e1bbcb1bc06",
      "cd0f7ad4e21f4b2580f9dd0c8d333586",
      "5adc970dab4346a9a54afbeeb81c91e0",
      "34988d7cfbbb42aeac37b7dfe5fc1288"
     ]
    },
    "id": "wU-b7Q8eBVca",
    "outputId": "5f992877-857f-4630-c9ae-78ee999679bf"
   },
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "mean_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    training_loss, mean_loss = train(model, DEVICE, train_loader, optimizer, epoch, max_epochs=EPOCHS)\n",
    "    test_loss, accuracy = test(model, DEVICE, test_loader, epoch)\n",
    "    training_losses += training_loss\n",
    "    mean_losses.append(mean_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"final accuracy: {accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKEVGF76x_Ee"
   },
   "source": [
    "We can visualize the output of the trained network on an example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "NL_rtLC2xXLp",
    "outputId": "f6d08cf8-d3f1-4636-f190-ed6421d29256"
   },
   "outputs": [],
   "source": [
    "trained_snn = model.snn.cpu()\n",
    "trained_readout_voltages = trained_snn(example_input.unsqueeze(1))\n",
    "plt.plot(trained_readout_voltages.squeeze(1).detach().numpy())\n",
    "\n",
    "plt.ylabel('Voltage [a.u.]')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjaJS_Hj2qW4"
   },
   "source": [
    "## Network with Spike Latency Encoding\n",
    "\n",
    "As we've mentioned above there are alternative ways of encoding and decoding the data to and from spikes. Here we go through two such alternative with the same network we've used before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4sGruNn8w49"
   },
   "source": [
    "As is the the outer training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EBQxwkW2FEh"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "from norse.torch.module import encode\n",
    "encode = importlib.reload(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0mJvDZx2zRi",
    "outputId": "ff5f030b-623f-41ee-e50b-df0f42ccfac2"
   },
   "outputs": [],
   "source": [
    "#from norse.torch.module import encode\n",
    "\n",
    "T = 32\n",
    "LR = 0.002\n",
    "INPUT_FEATURES = 28*28\n",
    "HIDDEN_FEATURES = 100\n",
    "OUTPUT_FEATURES = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "model = Model(\n",
    "    encoder=encode.SpikeLatencyLIFEncoder(T),\n",
    "    snn=SNN(\n",
    "      input_features=INPUT_FEATURES,\n",
    "      hidden_features=HIDDEN_FEATURES,\n",
    "      output_features=OUTPUT_FEATURES\n",
    "    ),\n",
    "    decoder=decode\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "3b858775951f42489a5e99bf258a9579",
      "efe654038a9f405784dd92ce0fc94641",
      "32ddf38476e84905b9837a73a2e51c69",
      "3d9918e3c7124eeea939f5d03f754c2e",
      "471b51adfd62431eb2cb1cb07e57dfaa",
      "eeda159d0d8c4f68a5072c61c8a148ec",
      "088c594b5d9a4d2fb7fe40aaece3715f",
      "c43606fcb05742bdab65e48b89160e23",
      "d0b06109fe624b7b89f254d271501421",
      "85dd1918d25e49e68d7fa33098b1a944",
      "1dcdbfd15aee439094c6629293a29ad2",
      "eb527019b41646298444cbd2d41fd61d",
      "3ef4a9dccdfe49ecb66766a2a35e609b",
      "401931c694c54d65af8ee39770c10725",
      "7607a137be384342b4477d8c2aa3c872",
      "cab564591c9c412b9e6e1b82bb5bdabb",
      "5dc2ae41b0fe44eb8a54dbfda5ad3662",
      "2bb875b41fdc4805943dff47a5213970",
      "69c0a6d00ebf47c58ea3b96fc7e57b05",
      "22564260e03e4c89a5b65696f090e101",
      "2890f00690c64ab3b1c2854c64a654f7",
      "8f6a1df4fda548869e1326a09868b3dc",
      "a9edd88e94544116a5187e0424b0c177",
      "6af440e96d7f4bc3b629029f237fe13b",
      "8327d4dcf9a243d090e99593fb6e2fd5",
      "a46a756afa2841e4867d4b9bf99482f4",
      "22d37cddba6347a3b8b2909dbce03fd5",
      "1c8d9211202a49eaa066eecba1fc933b",
      "683c5718d3bd471693ed66eec49bcdd3",
      "14dfca545dd24dc68b1062bedc704233",
      "0404b45b19884af6beb843d18e1b7ba7",
      "6e8be9fab26449e9a43b8005fb6f4ac5",
      "92c8bdb639ae4cecba7d02f36ab029ec",
      "05821971a2b44b29ba6d4845c292557f",
      "fda71ad25ca848429c1db23b866f16b3",
      "39a76cf8e4bb42f1b6132299dd8ac19e",
      "2a47df900af5446aa4a9221f273f76d6",
      "11fb619891d84f52a3324729dad1d25e",
      "dc6d60ac28be4447b284b3f132fcd029",
      "f7452107d5484825b40393f03f72a5fd",
      "c23f52e042654b7b9c2c6fe9105e2b3d",
      "7b784beef6104c2380fe70afaebc0205",
      "de6875ef3b6f4869acb712ca2db6a772",
      "c30319363add4b2aba55271ed6904bce",
      "9aee06638dbe495faea380dd1970d6fe",
      "1ebf55899c5d4cca97f0efe349e9d770",
      "8f308f906ea0445bad9543048f69ce41",
      "4f29018687b844e1beaf6cc6a7198ad2"
     ]
    },
    "id": "jynkfxjr4maa",
    "outputId": "45aa79eb-5e86-4325-9b10-40cce6000125"
   },
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "mean_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    training_loss, mean_loss = train(model, DEVICE, train_loader, optimizer, epoch, max_epochs=EPOCHS)\n",
    "    test_loss, accuracy = test(model, DEVICE, test_loader, epoch)\n",
    "    training_losses += training_loss\n",
    "    mean_losses.append(mean_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"final accuracy: {accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUQSr3GAQ_Wd"
   },
   "source": [
    "## Network with Poisson Encoded Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hx7vMD2SQ51V",
    "outputId": "b79ebdab-deea-4ac5-e5f4-8d714424a97e"
   },
   "outputs": [],
   "source": [
    "T = 32\n",
    "LR = 0.002\n",
    "INPUT_FEATURES = 28*28\n",
    "HIDDEN_FEATURES = 100\n",
    "OUTPUT_FEATURES = 10\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "model = Model(\n",
    "    encoder=encode.PoissonEncoder(T, f_max=20),\n",
    "    snn=SNN(\n",
    "      input_features=INPUT_FEATURES,\n",
    "      hidden_features=HIDDEN_FEATURES,\n",
    "      output_features=OUTPUT_FEATURES\n",
    "    ),\n",
    "    decoder=decode\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "990ed923e0c347958bce4ceeaa5484e0",
      "6c9442f6e98848078f4979473d10222e",
      "6c5f798c7342485f95287dc77a89119a",
      "d1f3a0ed896a486c8eba7cbfb929d036",
      "1b73683e800e4691ad6b38b3acb61b27",
      "ed6630afa2cf41f49bd26be65f103182",
      "08dd6a2ceeb3472cb574fd9fefb62e07",
      "0d9a635181f94dfe9e248b9f4902f0f8",
      "bfbd187ff861471d90448b5e805336f6",
      "84e7f2f4891f4c91ba0a8d8469d16b20",
      "971f5a7ac6f84271b90f042993681eed",
      "1fa7599ee6094a8c8e96a3d3d0c571f4",
      "c1cbd84429004c0085990ab4345a4767",
      "9129f0f4435147b38733be723bb940f5",
      "c051e4af46394ea6b04201c66071a9af",
      "ff09ad454d3f4ccbb27da78303ede1f9",
      "47a36f4376a7438d874fd74e66904407",
      "4c2139032dca4926a82dab6b16cfe9df",
      "69e979a4a4804e02baae9bb771fd58cd",
      "d930494b8fa1477288028042602f8bfa",
      "e49d0a23508941d3a66509c7e4ab1542",
      "be2c349fc768445c807efb9e6f234322",
      "ea141499b9e1445485417368364afc4b",
      "7b22a159c0f441488d9371e1268fe2eb",
      "d83ceb619ffe4de193b373b46785b9c5",
      "21ed7ad16b28448f9e9574b0ead5cbb1",
      "1a6a79f3ef22469a94d0c158518aaea2",
      "69d0ac9eb51e46f1b47b51d59c61b407",
      "b560d6a6173d426b82b779491e28033e",
      "42124470a0584e02b67c99d90bb237dd",
      "f9b5a586a44f4c6fa844575945552988",
      "6106151e6553435f963ae04e5b1784d0",
      "eee26a654fc240bf9ec3cab72e55808e",
      "dfc0b48867314fa3824e08f538924d0f",
      "378fa6ee5309489b8f5a7e3e45b7a955",
      "1fbe4bce97ba4016a4281f79ee812524",
      "f019ff0adcc04ae7ae6dff53e25adf45",
      "ae2c7cc3c7014c57a897adb095947cce",
      "a98a4e0a6654438fb884ded46862f12f",
      "5ae6dfc79b6d4b41a3ae4dbe151897ba",
      "52a67a8e585e43f7b880c0a7ccaa9bc9",
      "34bf1fb8465b41b7b856ebc1218e4f18",
      "966260f6138e40b98a467c2228ff3e50",
      "85b1a74aa55c4a6aac158560122006d5",
      "17f1c4e1a91e4b8bb1ce662feda382b1",
      "c0dc9f0d5c424d46b305aa31852c38bd",
      "9300acf406334c4286cdfab47f737c45",
      "7e9cd29064d948e8888bc200dde0b30c"
     ]
    },
    "id": "9u1HP4LTRnQF",
    "outputId": "5d919db4-c531-4cf2-f5b4-c497f728d008"
   },
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "mean_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    training_loss, mean_loss = train(model, DEVICE, train_loader, optimizer, epoch, max_epochs=EPOCHS)\n",
    "    test_loss, accuracy = test(model, DEVICE, test_loader, epoch)\n",
    "    training_losses += training_loss\n",
    "    mean_losses.append(mean_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)       \n",
    "    # print(f\"epoch: {epoch}, mean_loss: {mean_loss}, test_loss: {test_loss}, accuracy: {accuracy}\", flush=True)\n",
    "\n",
    "print(f\"final accuracy: {accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFLeAQPrkNbi"
   },
   "source": [
    "As can be seen from the training result, this combination of hyperparameters, decoding and encoding scheme performs worse than the alternative we've presented before. As with any machine learning approach one of the biggest challenges is to find a combination of these choices that works well. Sometimes theoretical knowledge helps in making these choices. For example it is well known that poisson encoded input will converge with $1/\\sqrt{T}$, where $T$ is the number of timesteps. So most likely the low number of timesteps ($T = 32$) contributes to the poor performance.\n",
    "\n",
    "In the next section we will see that choice of network architecture is also key in training performant spiking neural networks, just as it is for artifiicial neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2iFlyC-r40a"
   },
   "source": [
    "## Convolutional Networks\n",
    "\n",
    "The simple two layer recurrent spiking neural network we've defined above achieves a respectable ~96.5% accuracy after 10 training epochs. One common way\n",
    "to improve on this performance is to use convolutional neural networks. We define here two convolutional layers and one spiking classification layer. Just as in the recurrent spiking neural network before, we use a non-spiking leaky integrator for readout.\n",
    "\n",
    "The ```torch.nn.functional.max_pool2d``` on binary values is a logical ```or``` operation on its inputs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEcU9GMdBc8r"
   },
   "outputs": [],
   "source": [
    "from norse.torch.module.leaky_integrator import LILinearCell\n",
    "from norse.torch.functional.lif import LIFFeedForwardState\n",
    "from norse.torch.functional.leaky_integrator import LIState\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,  num_channels=1, feature_size=28, method=\"super\", alpha=100\n",
    "    ):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    "        self.features = int(((feature_size - 4) / 2 - 4) / 2)\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(num_channels, 20, 5, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = torch.nn.Linear(self.features * self.features * 50, 500)\n",
    "        self.lif0 = LIFCell(p=LIFParameters(method=method, alpha=alpha))\n",
    "        self.lif1 = LIFCell(p=LIFParameters(method=method, alpha=alpha))\n",
    "        self.lif2 = LIFCell(p=LIFParameters(method=method, alpha=alpha))\n",
    "        self.out = LILinearCell(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.shape[0]\n",
    "        batch_size = x.shape[1]\n",
    "        \n",
    "        # specify the initial states\n",
    "        s0 = s1 = s2 = so = None\n",
    "\n",
    "        voltages = torch.zeros(\n",
    "            seq_length, batch_size, 10, device=x.device, dtype=x.dtype\n",
    "        )\n",
    "\n",
    "        for ts in range(seq_length):\n",
    "            z = self.conv1(x[ts, :])\n",
    "            z, s0 = self.lif0(z, s0)\n",
    "            z = torch.nn.functional.max_pool2d(z, 2, 2)\n",
    "            z = 10 * self.conv2(z)\n",
    "            z, s1 = self.lif1(z, s1)\n",
    "            z = torch.nn.functional.max_pool2d(z, 2, 2)\n",
    "            z = z.view(-1, 4 ** 2 * 50)\n",
    "            z = self.fc1(z)        \n",
    "            z, s2 = self.lif2(z, s2)\n",
    "            v, so = self.out(torch.nn.functional.relu(z), so)\n",
    "            voltages[ts, :, :] = v\n",
    "        return voltages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "dWuEYbSK6BVc",
    "outputId": "0d2b5141-d91b-44ff-8d3e-59832ea2d3a3"
   },
   "outputs": [],
   "source": [
    "img, label = train_data[2]\n",
    "\n",
    "plt.matshow(img[0])\n",
    "plt.show()\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oiIMzaks6wVp"
   },
   "source": [
    "Just as we did we can visualise the output of the untrained convolutional network on a sample input. Notice that compared to the previous untrained\n",
    "output the first non-zero membrane trace values appear later. This is due to \n",
    "the fact that there is a finite delay for each added layer in the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "ej6ADCz7zYNj",
    "outputId": "ff8a6e9f-df2b-4052-d8c4-3ff508ffe231"
   },
   "outputs": [],
   "source": [
    "T = 48\n",
    "example_encoder = encode.ConstantCurrentLIFEncoder(T)\n",
    "example_input = example_encoder(img)\n",
    "example_snn = ConvNet()\n",
    "example_readout_voltages = example_snn(example_input.unsqueeze(1))\n",
    "\n",
    "plt.plot(example_readout_voltages.squeeze(1).detach().numpy())\n",
    "plt.ylabel('Voltage [a.u.]')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F0ZP9KzzUKiG",
    "outputId": "087898c3-bfef-4dda-a037-9bb79c0f580f"
   },
   "outputs": [],
   "source": [
    "T = 48\n",
    "LR = 0.001\n",
    "EPOCHS = 5 # Increase this for improved accuracy\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "model = Model(\n",
    "    encoder=encode.ConstantCurrentLIFEncoder(T),\n",
    "    snn=ConvNet(alpha=80),\n",
    "    decoder=decode\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "ad67a7f23c9e452a932a1fc9128a7190",
      "50a7821a77824429b29fed56bc3818ae",
      "91b005a8c65647fb8eb61c18cebafc03",
      "24f89a01ee774a6d801cb35e3c6e9193",
      "747d08455ba74fe09a719a982addbe42",
      "860bebe74a194db3a3635a5311294706",
      "a00debf1db644d5e9fdacc226434676c",
      "aa416f4f7839451e9a0ec68277278a19",
      "0eb9acebcb6a4c54b50718506ba5e270",
      "6d9601fa6d834534a6124421c60862aa",
      "525d5c3e5f0c45c883706b06739301bb",
      "f0a9d5f9ec0348c3a5dbb497b1300318",
      "99d25e55cda04ff1a7c19e91393409c4",
      "ffdaac8f4a6246468cdf1b0ae7e287a7",
      "8e57797683134cf99afe3e7e368cce75",
      "32d93c0d270f40ebbc384d8ed3b06240",
      "6fe40cc40b67481ca772efa707102250",
      "e4c7581f302843c9a9cdec0893cc6e0b",
      "651ca62a948e435d82f76faac71c717d",
      "79718e60cdfc43e6b810639581520cff",
      "059e662d13164f4db032a3c2a2e68d7e",
      "3da54ed82b004184b4053da8387cd4d9",
      "424b45fb613f440ab88786c9594b42dc",
      "e6aa0c3139a646f2b8f68125a4816aca",
      "f66c2bd6087745578d46f09a6c424554",
      "9e247f32d7454a9db2431fd75b22d583",
      "178049a186db43bd960f7b16c92fc8cf",
      "cc00703fde694eab899cf40f72b854bb",
      "f561c7182c0c4534ae890fc81b19dabe",
      "4b87384f7913442b81fbae1bd7aedd86",
      "1437267691404da0a7aeb3b087ae989a",
      "dec0cccb5d5c4a7281b71151d4b0ac7f",
      "cf04ca2f8d0441088520d6e463c7e2c3",
      "0a7f646b3fc6457799100371f8870c04",
      "b821a47bb7ef40a6b2f3e0fed62213af",
      "1438cb1be47842ea87ff2ec8fc0ffdac",
      "c1a451f2d31f46e2bcd36a68180308bc",
      "55e802c92c6443bd9ea90ff62d641deb",
      "591f49916bc349a19dbb3365b8d2b046",
      "ee4e5845ab2f4f07ba11dfc9d1f73ec9",
      "dd75cfad6f4f40a687e0fdfde9ac22de",
      "88d4880a1e494778ad5e356e8680f323",
      "199c50a26d4d4d4e9d6cd6bddb07db69",
      "e4a5a0aed7a24145a18fcf3233316657",
      "8a94aa7fde084b7a9a434043dc648381",
      "23ef32e7c25946c9918008978eb836ca",
      "130b66bce2a54c19bddc22802ea2bc9d",
      "063c92c1db58422f9069a750e2f6dbc0"
     ]
    },
    "id": "IL46G6sdVxoN",
    "outputId": "43f9c98e-3d95-4a56-bdca-8b1cf76370d2"
   },
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "mean_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "\n",
    "for epoch in trange(EPOCHS):\n",
    "    training_loss, mean_loss = train(model, DEVICE, train_loader, optimizer, epoch, max_epochs=EPOCHS)\n",
    "    test_loss, accuracy = test(model, DEVICE, test_loader, epoch)\n",
    "    training_losses += training_loss\n",
    "    mean_losses.append(mean_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)       \n",
    "\n",
    "print(f\"final accuracy: {accuracies[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "R6aZXCqOVZjI",
    "outputId": "1e8d91b1-9d7f-4fee-abcc-f664cb156a20"
   },
   "outputs": [],
   "source": [
    "trained_snn = model.snn.cpu()\n",
    "\n",
    "trained_readout_voltages = trained_snn(example_input.unsqueeze(1))\n",
    "\n",
    "print(trained_readout_voltages.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(trained_readout_voltages[:,:,i].squeeze(1).detach().numpy(), label=f'{i}')\n",
    "\n",
    "plt.ylabel('Voltage [a.u.]')\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YKMRqTOfO9l"
   },
   "source": [
    "As we can see the output neuron for the label '4' indeed integrates\n",
    "the largest number of spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "pRjmCTIdcawn",
    "outputId": "d56e73b0-22df-4162-eb4f-096763dc317b"
   },
   "outputs": [],
   "source": [
    "plt.matshow(np.squeeze(img,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_OUx3IKlQLE"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "We've seen that on a small supervised learning task it is relatively easy to define spiking neural networks that perform about as well as non-spiking artificial networks. The network architecture used is in direct correspondence to one that would be used to solve such a task with an artificial neural network, with the non-linearities replaced by spiking units. \n",
    "\n",
    "The remaining difference in performance might be related to a number of choices:\n",
    "- hyperparameters of the optimizer\n",
    "- precise architecture (e.g. dimensionality of the classification layer)\n",
    "- weight initialisation\n",
    "- decoding scheme\n",
    "- encoding scheme\n",
    "- number of integration timesteps\n",
    "\n",
    "The first three points are in common with the problems encountered in the design and training of artificial neural network classifiers. Comparatively little is known though about their interplay for spiking neural network architectures.\n",
    "\n",
    "The last three points are special to spiking neural network problems simply because of their constraints on what kind of data they can process naturally. While their interplay has certainly been investigated in the literature, it is unclear if there is a good answer what encoding and decoding should be chosen in general.\n",
    "\n",
    "Finally we've also omitted any regularisation or data-augementation, which could further improve performance. Common techniques would be to introduce weight decay or penalise unbiologically high firing rates. In the simplest case those can enter as addtional terms in the loss function we've defined above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
