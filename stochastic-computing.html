
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Stochastic Computing &#8212; Norse Tutorial Notebook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Norse Tutorial Notebook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="README.html">
                    Norse Notebook Tutorials
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro_spikes.html">
   Spiking neurons in PyTorch
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro_norse.html">
   Spiking neural networks with Norse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="intro_plotting.html">
   Simulating and plotting neurons
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Supervised Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="mnist_classifiers.html">
   Training an MNIST classifier
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="poker-dvs_classifier.html">
   Training a classifier on the event-based POKER-DVS dataset
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Real-time event processing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="edge_detector.html">
   Detecting edges from event data with Norse
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neuroscience
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="parameter-learning.html">
   Parameter learning in SNN with Norse
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stp_example.html">
   Spike Time Dependent Plasticity
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Miscellaneous
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="high-performance-computing.html">
   High-Performance Computing with Norse and PyTorch Lightning
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/norse/notebooks"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/norse/notebooks/issues/new?title=Issue%20on%20page%20%2Fstochastic-computing.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/stochastic-computing.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-0-install-requirements">
   Step 0: Install Requirements
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-neuron-model">
   Step 1: Neuron Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-task">
   Step 2: Task
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-training">
   Step 3: Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-evaluating-the-result">
   Step 4: Evaluating the Result
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Stochastic Computing</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-0-install-requirements">
   Step 0: Install Requirements
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-1-neuron-model">
   Step 1: Neuron Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-2-task">
   Step 2: Task
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-3-training">
   Step 3: Training
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#step-4-evaluating-the-result">
   Step 4: Evaluating the Result
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="stochastic-computing">
<h1>Stochastic Computing<a class="headerlink" href="#stochastic-computing" title="Permalink to this headline">#</a></h1>
<p>The goal of this part of the workshop is to explore a simple example
of stochastic computing with spiking neurons.</p>
<section id="step-0-install-requirements">
<h2>Step 0: Install Requirements<a class="headerlink" href="#step-0-install-requirements" title="Permalink to this headline">#</a></h2>
<p>First of all, we will need to install Norse. Please run the cell below. Read on while it’s running.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>!pip install norse --quiet

import torch
import norse
</pre></div>
</div>
</section>
<section id="step-1-neuron-model">
<h2>Step 1: Neuron Model<a class="headerlink" href="#step-1-neuron-model" title="Permalink to this headline">#</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>


<span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">LIFRefracRecurrentCell</span>
<span class="kn">from</span> <span class="nn">norse.torch.functional.threshold</span> <span class="kn">import</span> <span class="n">superspike_fn</span>
<span class="kn">from</span> <span class="nn">norse.torch.functional.lif_refrac</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">lif_refrac_feed_forward_step</span><span class="p">,</span>
    <span class="n">lif_refrac_step</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">norse.torch.functional.lif_refrac</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LIFRefracFeedForwardState</span><span class="p">,</span>
    <span class="n">LIFRefracState</span><span class="p">,</span>
    <span class="n">LIFRefracParameters</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">norse.torch.functional.lif</span> <span class="kn">import</span> <span class="n">LIFFeedForwardState</span><span class="p">,</span> <span class="n">LIFState</span><span class="p">,</span> <span class="n">LIFParameters</span>
<span class="kn">from</span> <span class="nn">norse.torch.functional.encode</span> <span class="kn">import</span> <span class="n">poisson_encode</span>


<span class="k">class</span> <span class="nc">LIFRefracNeurons</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LIFRefracNeurons</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">K</span> <span class="o">=</span> <span class="n">K</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="n">N</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">v_leak</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="mf">1.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="mf">10.0</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">lif_parameter</span> <span class="o">=</span> <span class="n">LIFParameters</span><span class="p">(</span>
            <span class="n">v_leak</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">v_leak</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;super&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">lif_refrac</span> <span class="o">=</span> <span class="n">LIFRefracParameters</span><span class="p">(</span><span class="n">lif_parameter</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rho</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cell</span> <span class="o">=</span> <span class="n">LIFRefracRecurrentCell</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">lif_refrac</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="n">T</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">s0</span> <span class="o">=</span> <span class="n">LIFRefracState</span><span class="p">(</span>
            <span class="n">LIFState</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="mf">0.9</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">refrac</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">voltages</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
            <span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cell</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">ts</span><span class="p">,</span> <span class="p">:],</span> <span class="n">s0</span><span class="p">)</span>
            <span class="n">r</span> <span class="o">=</span> <span class="n">superspike_fn</span><span class="p">(</span><span class="n">s0</span><span class="o">.</span><span class="n">rho</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">100.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">z</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">refrac</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
            <span class="n">voltages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s0</span><span class="o">.</span><span class="n">lif</span><span class="o">.</span><span class="n">v</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">refrac</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">voltages</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-2-task">
<h2>Step 2: Task<a class="headerlink" href="#step-2-task" title="Permalink to this headline">#</a></h2>
<p>The goal will be to approximate a binary probability distribution on three binary variables
<span class="math notranslate nohighlight">\(z_1, z_2, z_3\)</span> represented by the refractory state <span class="math notranslate nohighlight">\(\rho\)</span> of three neurons. The correlation between the three refractory state variables can be computed in the following way</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">three_point_correlations_func</span><span class="p">(</span><span class="n">rho</span><span class="p">):</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">rho</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">rb0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">rb1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">rb2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="mi">1</span> <span class="o">-</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">rho</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">2</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;atb,dtb,gtb -&gt; badg&quot;</span><span class="p">,</span> <span class="n">rb0</span><span class="p">,</span> <span class="n">rb1</span><span class="p">,</span> <span class="n">rb2</span><span class="p">)</span> <span class="o">/</span> <span class="n">T</span>
</pre></div>
</div>
<p>Question (Optional): Can you think of a way how to implement this for an
arbitrary number of neurons?</p>
<p>We will generate the target distribution by sampling from a population of refractory
neurons, that way we can be reasonably sure that the model can be trained quickly
to approximate the target distribution.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_target_distribution</span><span class="p">(</span><span class="n">timesteps</span><span class="p">,</span> <span class="n">batch_dimension</span><span class="p">,</span> <span class="n">input_features</span><span class="p">):</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">H</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">batch_dimension</span><span class="p">,</span> <span class="n">input_features</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">poisson_encode</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span> <span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">n_target</span> <span class="o">=</span> <span class="n">LIFRefracNeurons</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">refrac_t</span><span class="p">,</span> <span class="n">voltages_t</span> <span class="o">=</span> <span class="n">n_target</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">readout_t</span> <span class="o">=</span> <span class="n">refrac_t</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>
    <span class="n">p_target</span> <span class="o">=</span> <span class="n">three_point_correlations_func</span><span class="p">(</span><span class="n">readout_t</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">p_target</span> <span class="o">=</span> <span class="n">p_target</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p_target</span>
</pre></div>
</div>
<p>To plot the target we can use the following helper function</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">target_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.35</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">p_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p_</span><span class="si">{t}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;</span><span class="si">{0:03b}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$p(z)$&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$z$&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we generate a target distribution.</p>
<p>Once you’ve run the notebook to completion, you can
consider doing one of the following Tasks:</p>
<ul class="simple">
<li><p>Vary the number of timesteps, how to you expect fidelity of the approximation to behave?</p></li>
<li><p>Change the number of visible units (N) and number of poisson noise sources (H), what do you observe?</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># number of visible units</span>
<span class="n">H</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># number of synapses connected to poisson noise sources</span>
<span class="n">B</span> <span class="o">=</span> <span class="mi">32</span>  <span class="c1"># batch dimension</span>
<span class="n">T</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># number of timesteps to integrate (increase to get better sampling accuracy)</span>
<span class="n">rho</span> <span class="o">=</span> <span class="mi">20</span>  <span class="c1"># refractory time in timesteps</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>

<span class="n">p_target</span> <span class="o">=</span> <span class="n">generate_target_distribution</span><span class="p">(</span>
    <span class="n">timesteps</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">batch_dimension</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">input_features</span><span class="o">=</span><span class="n">H</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">()</span>
<span class="n">target_plot</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">p_target</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="step-3-training">
<h2>Step 3: Training<a class="headerlink" href="#step-3-training" title="Permalink to this headline">#</a></h2>
<p>The goal of the training procedure will be to minimize the <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a> between the target distribution <span class="math notranslate nohighlight">\(p_t\)</span> and the batch-averaged sampled distribution <span class="math notranslate nohighlight">\(p_s\)</span>. In the machine-learning language the Kullback-Leibler divergence is one example of a loss-function and luckily PyTorch provides an <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html">implementation</a>. This is another good example where relying on a widely used library saves us a lot of implementation time.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">trange</span>

<span class="n">neurons</span> <span class="o">=</span> <span class="n">LIFRefracNeurons</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">neurons</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="mi">40</span>  <span class="c1"># number of epochs to optimize</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># sample new poisson noise for every iteration</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">poisson_encode</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">H</span><span class="p">),</span> <span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># compute the refractory state and voltage traces</span>
    <span class="n">refrac</span><span class="p">,</span> <span class="n">voltages</span> <span class="o">=</span> <span class="n">neurons</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="c1"># the first three neurons in each batch are our readout neurons</span>
    <span class="n">readout</span> <span class="o">=</span> <span class="n">refrac</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">]</span>

    <span class="c1"># compute sampled probability distribution</span>
    <span class="n">p_f</span> <span class="o">=</span> <span class="n">three_point_correlations_func</span><span class="p">(</span><span class="n">refrac</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># batch averaged Kullback-Leibler divergence</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">kl_div</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">)),</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;batchmean&quot;</span>
    <span class="p">)</span>

    <span class="c1"># propagate gradient to parameters through time and take optimisation step</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>
    <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>


<span class="c1"># save all the training results</span>
<span class="n">basepath</span> <span class="o">=</span> <span class="s2">&quot;results/stochastic&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;refrac.npy&quot;</span><span class="p">),</span> <span class="n">refrac</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;p_target.npy&quot;</span><span class="p">),</span> <span class="n">p_target</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;p_f.npy&quot;</span><span class="p">),</span> <span class="n">p_f</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;losses.npy&quot;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">losses</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;voltages.npy&quot;</span><span class="p">),</span> <span class="n">voltages</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
<p>The model should converge to a loss of ~0.02-0.04.</p>
<p>Tasks / Questions:</p>
<ul class="simple">
<li><p>What could be done to improve upon this result?</p></li>
<li><p>Change the input poisson noise, what happens?</p></li>
<li><p>Find out about different <a class="reference external" href="https://pytorch.org/docs/stable/optim.html">optimisers</a> and try another one.</p></li>
</ul>
</section>
<section id="step-4-evaluating-the-result">
<h2>Step 4: Evaluating the Result<a class="headerlink" href="#step-4-evaluating-the-result" title="Permalink to this headline">#</a></h2>
<p>Every scientist knows that a great plot is more than half of the reward.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">basepath</span> <span class="o">=</span> <span class="s2">&quot;results/stochastic&quot;</span>

<span class="n">refrac</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;refrac.npy&quot;</span><span class="p">)))</span>
<span class="n">p_target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;p_target.npy&quot;</span><span class="p">)))</span>
<span class="n">p_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;p_f.npy&quot;</span><span class="p">)))</span>
<span class="n">losses</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="s2">&quot;losses.npy&quot;</span><span class="p">)))</span>
</pre></div>
</div>
<p>The following code is not really part of the workshop, but is necessary to
create a decent (enough) looking figure of the results.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.collections</span> <span class="kn">import</span> <span class="n">PatchCollection</span><span class="p">,</span> <span class="n">LineCollection</span>
<span class="kn">from</span> <span class="nn">matplotlib.patches</span> <span class="kn">import</span> <span class="n">Rectangle</span>


<span class="k">def</span> <span class="nf">negedge</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="n">z_prev</span>


<span class="k">def</span> <span class="nf">posedge</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">z</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">z_prev</span><span class="p">)</span>


<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;ytick.left&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;ytick.labelleft&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.spines.left&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.spines.right&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.spines.top&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;axes.spines.bottom&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;legend.frameon&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">sampling_figure</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">refrac</span><span class="p">):</span>
    <span class="n">T</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">refrac</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">N</span> <span class="o">=</span> <span class="mi">3</span>

    <span class="n">posedges</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">negedges</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">z_prev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">refrac</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">refrac</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="mf">1.2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.6</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticklabels</span><span class="p">([</span><span class="s2">&quot;$z_1$&quot;</span><span class="p">,</span> <span class="s2">&quot;$z_2$&quot;</span><span class="p">,</span> <span class="s2">&quot;$z_3$&quot;</span><span class="p">,</span> <span class="s2">&quot;$z_4$&quot;</span><span class="p">,</span> <span class="s2">&quot;$z_5$&quot;</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s2">&quot;left&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">T</span><span class="p">):</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">refrac</span><span class="p">[</span><span class="n">ts</span><span class="p">]</span>
        <span class="n">posedges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posedge</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">))</span>
        <span class="n">negedges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">negedge</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">z_prev</span><span class="p">))</span>
        <span class="n">z_prev</span> <span class="o">=</span> <span class="n">z</span>

    <span class="n">posedges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">posedges</span><span class="p">)</span>
    <span class="n">negedges</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">negedges</span><span class="p">)</span>

    <span class="n">lines</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">rects</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">facecolor</span> <span class="o">=</span> <span class="s2">&quot;black&quot;</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">posedges</span><span class="p">[</span><span class="mi">200</span><span class="p">:</span><span class="mi">400</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span><span class="o">.</span><span class="n">indices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">t_r</span> <span class="o">=</span> <span class="n">negedges</span><span class="p">[</span><span class="mi">200</span><span class="p">:</span><span class="mi">400</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span><span class="o">.</span><span class="n">indices</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">ts</span><span class="p">,</span> <span class="n">tf</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">t_r</span><span class="p">):</span>
            <span class="n">rect</span> <span class="o">=</span> <span class="n">Rectangle</span><span class="p">((</span><span class="n">ts</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">),</span> <span class="n">tf</span> <span class="o">-</span> <span class="n">ts</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">line</span> <span class="o">=</span> <span class="p">[(</span><span class="n">ts</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">),</span> <span class="p">(</span><span class="n">ts</span><span class="p">,</span> <span class="n">k</span> <span class="o">*</span> <span class="mf">1.2</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)]</span>
            <span class="n">rects</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">rect</span><span class="p">)</span>
            <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

    <span class="n">pc</span> <span class="o">=</span> <span class="n">PatchCollection</span><span class="p">(</span><span class="n">rects</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="n">facecolor</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">lc</span> <span class="o">=</span> <span class="n">LineCollection</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">voltages</span><span class="p">[</span><span class="mi">200</span><span class="p">:</span><span class="mi">400</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="o">+</span> <span class="n">k</span> <span class="o">*</span> <span class="mf">1.2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;$v_</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">$&quot;</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">add_collection</span><span class="p">(</span><span class="n">pc</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Neuron&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;T [ms]&quot;</span><span class="p">)</span>
    <span class="c1"># ax.add_collection(lc)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.15</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">figure_stochastic_computing</span><span class="p">(</span><span class="n">p_f</span><span class="p">,</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">refrac</span><span class="p">):</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mf">0.35</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
    <span class="n">gs</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_gridspec</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">ax_sampling</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">ax_prob</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="n">ax_loss</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="n">p_f_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">p_f_min</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">p_f_max</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">p_f</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">ax_sampling</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;A&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax_sampling</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;normal&quot;</span>
    <span class="p">)</span>
    <span class="n">sampling_figure</span><span class="p">(</span><span class="n">ax_sampling</span><span class="p">,</span> <span class="n">refrac</span><span class="p">)</span>

    <span class="c1"># plot the probabilities</span>

    <span class="n">ax_prob</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax_prob</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;normal&quot;</span>
    <span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="o">-</span> <span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">p_f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p_s$&quot;</span>
    <span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="o">+</span> <span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">p_target</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">width</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;$p_</span><span class="si">{t}</span><span class="s2">$&quot;</span><span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;</span><span class="si">{0:03b}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)],</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$p(z)$&quot;</span><span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;$z$&quot;</span><span class="p">)</span>
    <span class="n">ax_prob</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span> <span class="o">-</span> <span class="n">width</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span>
        <span class="n">p_f_mean</span><span class="p">,</span>
        <span class="n">yerr</span><span class="o">=</span><span class="p">[</span><span class="n">p_f_mean</span> <span class="o">-</span> <span class="n">p_f_min</span><span class="p">,</span> <span class="n">p_f_max</span> <span class="o">-</span> <span class="n">p_f_mean</span><span class="p">],</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
        <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;.k&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">ax_loss</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
        <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="s2">&quot;C&quot;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax_loss</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="s2">&quot;medium&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;normal&quot;</span>
    <span class="p">)</span>
    <span class="n">ax_loss</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
    <span class="n">ax_loss</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$KL(p_s | p_t)$&quot;</span><span class="p">)</span>
    <span class="n">ax_loss</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>
</div>
<p>The resulting plot shows part of the neuron membrane traces of the three readout neurons, the value of the binary refractory state variables is indicated by gray shading (A). We also see how well the sampled distribution approximates the target distribution (B). Finally we plot the Kulback-Leibler divergence (C).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">figure_stochastic_computing</span><span class="p">(</span><span class="n">p_f</span><span class="p">,</span> <span class="n">p_target</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">refrac</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;stochastic_computing.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
</pre></div>
</div>
<!-- #region -->
<p>The same kind of experiment can be repeated for 5 variables. Below
is an example of one such run.</p>
<p><img alt="" src="https://raw.githubusercontent.com/norse/norse-hbp-workshop/main/images/stochastic_computing.png" /></p>
<!-- #endregion -->
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "norse/notebooks",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Norse authors<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>